{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Classificação: Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://somostera.com/_nuxt/img/7eecdb7.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm Up\n",
    "\n",
    "![image.png](https://media.giphy.com/media/l0Ex47BWhZ7bsaKcg/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectativas!\n",
    "\n",
    "O que vocês esperam da aula de hoje?\n",
    "\n",
    "![image.png](https://img.buzzfeed.com/buzzfeed-static/static/enhanced/web04/2012/2/14/17/enhanced-buzz-8358-1329258536-95.jpg?downsize=800:*&output-format=auto&output-quality=auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "> Avaliar se existem fatores que influenciam na promoção dos funcionários\n",
    "\n",
    "### Contexto\n",
    "> O RH da empresa está se tornando mais seletivo ao contratar novos funcionários. Dessa forma, ele quer entender o perfil de promoção dos funcionários para que no processo de seleção algum desses fatores sejam considerados. Além disso, um modelo de predição poderia ajudar na definição do budget de promoção. Você faz parte da área de **Data Science** dessa empresa, e precisa encontrar alguns insights que subsidiem o RH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "> TBD\n",
    "\n",
    "### Updated at\n",
    "> 30/Jan/2020 by Tera-DSC Team\n",
    "\n",
    "### Dataset\n",
    "> Dados históricos dos funcionários da empresa.\n",
    "\n",
    "### Warning\n",
    "> Dados sensíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regressão** ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://media.giphy.com/media/NsuQixwGTHy8M/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O modelo de regressão logística é semelhante ao modelo de regressão linear. No entanto, no modelo logístico a variável resposta $ Y_i $ é binária. Uma variável binária assume dois valores, como por exemplo, $ Y_i=0 $ e $ Y_i=1, $ denominados \"fracasso\" e \"sucesso\", respectivamente. Neste caso, \"sucesso\" é o evento de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferença entre Distribuição Linear e Logística\n",
    "![image.png](https://estatsite.files.wordpress.com/2018/08/linear_vs_logistic_regression.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- importando as libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
    "                             roc_auc_score, log_loss, plot_confusion_matrix, roc_curve, auc, plot_roc_curve)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (22,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- setando parâmetros de font\n",
    "sns.set_context(\"notebook\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- carregando o dataset\n",
    "df = pd.read_excel('../data/Base Analytics.xlsx', sheet_name='Censo sem Estagiário')\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- apresentando as dimensões do dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando o tipo das variáveis\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando os nomes das colunas\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritnando a quantidade de missing values\n",
    "null_count = df.isnull().sum().sort_values(ascending=False)\n",
    "null_percentage = null_count / len(df)\n",
    "pd.DataFrame(data=[null_count, null_percentage],\n",
    "             index=['null_amount', 'null_ratio']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando algumas métricas dos dados numéricos do dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Será que eu posso utilizar todo o Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- retornando menor data de admissão\n",
    "min(df['Admissão'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- filtrando pela data de admissão\n",
    "df_ano = df[df['Admissão'] >= '2011-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- retornando o tamanho do dataset\n",
    "df_ano.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando os missing values do dataset\n",
    "null_count = df_ano.isnull().sum().sort_values(ascending=False)\n",
    "null_percentage = null_count / len(df_ano)\n",
    "pd.DataFrame(data=[null_count, null_percentage],\n",
    "             index=['null_amount', 'null_ratio']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição das Idades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando um histograma da idade de admissão dos funcionários\n",
    "_ = sns.distplot(df_ano['Idade na Admissão'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hora Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando o gráfico das horas extras\n",
    "_ = sns.distplot(df_ano['Hora Extra 2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- preenchendo os missing values com flags\n",
    "df_ano['Hora Extra 2016'].fillna(-100, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando o hostograma das horas extras\n",
    "_ = sns.distplot(df_ano['Hora Extra 2016'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual a idade de desligamento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando o histograma da idade de desligamento\n",
    "_ = sns.distplot(df_ano['Idade Atual/ Desligamento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual outros gráficos vocês fariam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.distplot(df_ano['Tempo de Casa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando boxplot da promoção pelo tempo de casa\n",
    "_ = sns.boxplot(x=df_ano['PROMOVIDO'], y=df_ano['Tempo de Casa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- separando a variável do dataset de análise\n",
    "X = df_ano.drop(columns=['PROMOVIDO'])\n",
    "y = df_ano['PROMOVIDO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- separando os dados para treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando a Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- guardando o algoritmo de regressão logística\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando o algoritmo \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#-- predizendo as respostas\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- selecionadndo apenas as variáveis númericas\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df_ano.select_dtypes(include=numerics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um dataset novo\n",
    "df_ano_numeric = df_ano.select_dtypes(include=numerics).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- selecionando as colunas desse novo dataset\n",
    "df_ano_numeric = df_ano_numeric.drop(columns=['ADP', 'Cod.Cargo', 'Cod.Cargo Admissão', 'CC', 'Hora Extra 2016', 'Hora Negativa 2016', 'Ad. Noturno 2016', 'Absenteísmo 2016', 'Hora Extra 2017', 'Hora Negativa 2017', 'Ad. Noturno 2017', 'Absenteísmo 2017', 'Banda', '2012/13 Goal Achievement'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando o head do novo dataset\n",
    "df_ano_numeric.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando os missing values do dataset\n",
    "null_count = df_ano_numeric.isnull().sum().sort_values(ascending=False)\n",
    "null_percentage = null_count / len(df_ano_numeric)\n",
    "pd.DataFrame(data=[null_count, null_percentage],\n",
    "             index=['null_amount', 'null_ratio']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- removendo as colunas de 2013/14 e 2014/15\n",
    "df_ano_numeric.drop(columns=['2013/14 Goal Achievement', '2014/15 Goal Achievement'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- preenchendo os missing values\n",
    "df_ano_numeric.fillna(method='bfill', inplace=True)\n",
    "df_ano_numeric.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando se os missing values do dataset foram todas preenchidos\n",
    "null_count = df_ano_numeric.isnull().sum().sort_values(ascending=False)\n",
    "null_percentage = null_count / len(df_ano_numeric)\n",
    "pd.DataFrame(data=[null_count, null_percentage],\n",
    "             index=['null_amount', 'null_ratio']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as dimensões\n",
    "df_ano_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando os tipos das variáveis\n",
    "df_ano_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando os datasets para análise\n",
    "X = df_ano_numeric.drop(columns=['PROMOVIDO'])\n",
    "y = df_ano_numeric['PROMOVIDO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- separando a parte de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- apllicando o algoritmo\n",
    "logreg.fit(X_train, y_train)\n",
    "#-- calculando a predição\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando os cinco primeiros valores da predição\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando a acuracia do teste\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy (test): {accuracy_test*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão, Precisão, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando a matriz de confusão\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando a matrix de confusão\n",
    "_ = plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando as métricas de precisão e recall\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definições\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando a ROC\n",
    "_= plot_roc_curve(logreg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando as probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- calculando a probabilidade dos teste\n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando a probabilidade\n",
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- comparando as respostas\n",
    "preds_df = pd.DataFrame(data=[y_pred_proba, y_test.astype(str)],\n",
    "                        index=['Prediction', 'True Value']).T\n",
    "\n",
    "preds_df['Prediction'] = preds_df['Prediction'].astype(float)\n",
    "preds_df['True Value'] = preds_df['True Value'].astype(str)\n",
    "\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = preds_df[preds_df['True Value'] == '0']\n",
    "_ = sns.distplot(teste['Prediction'],  kde=False, label='Não Promov')\n",
    "teste1 = preds_df[preds_df['True Value'] == '1']\n",
    "_ = sns.distplot(teste1['Prediction'],  kde=False, label='Promov')\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.title('Não Promovido X Promovido')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Quantidade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- ajustando a probabilidade\n",
    "y_pred_customizado = y_pred_proba >= 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as novas métricas\n",
    "print(classification_report(y_test, y_pred_customizado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras métricas populares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'auc (test): {roc_auc_score(y_test, y_pred_proba):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- métrica - qt menor melhor\n",
    "print(f'log loss (test): {log_loss(y_test, y_pred_proba):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = logreg.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- comparando os resultados do modelo de treino com o de teste\n",
    "print(f'auc (train): {roc_auc_score(y_train, y_pred_proba_train):.4f}')\n",
    "print(f'auc (test): {roc_auc_score(y_test, y_pred_proba):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentando melhorar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando os nomes das colunas\n",
    "df_ano.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- selecionando as colunas do dataset\n",
    "df_ano_misto = df_ano[['Tempo de Casa', 'Idade Atual/ Desligamento', 'Idade na Admissão', '2013/14 Goal Achievement', '2014/15 Goal Achievement', '2015/16 Goal Achievement', '2016/17 Goal Achievement', 'Estado Civil', 'Educação', 'Sexo', 'PROMOVIDO']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando o head do dataset\n",
    "df_ano_misto.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- removendo as colunas de 2013/14 e 2014/15\n",
    "df_ano_misto.drop(columns=['2013/14 Goal Achievement', '2014/15 Goal Achievement'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- preenchendo os missing values\n",
    "df_ano_misto.fillna(method='bfill', inplace=True)\n",
    "df_ano_misto.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando se não existem mais missing values no dataset\n",
    "df_ano_misto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- transformando os dados discretos em dummies\n",
    "pd.get_dummies(df_ano_misto['Estado Civil']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando a função dummies\n",
    "df_dummies = pd.get_dummies(df_ano_misto, columns=['Estado Civil', 'Educação', 'Sexo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando o head\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- separando os datasets\n",
    "X = df_dummies.drop(columns=['PROMOVIDO'])\n",
    "y = df_dummies['PROMOVIDO']\n",
    "\n",
    "#-- splitando em ds de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando o algoritmo\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred  = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- verificando a métrica log loss\n",
    "print(f'log loss (test): {log_loss(y_test, y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando a matrix de confusão\n",
    "_ = plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as novas métricas\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- copiando o dataset\n",
    "df_no_outliers = df_dummies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando os outliers\n",
    "sns.boxplot(df_no_outliers['Tempo de Casa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando os outliers\n",
    "sns.boxplot(df_no_outliers['Idade na Admissão'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando os outliers\n",
    "sns.boxplot(df_no_outliers['2015/16 Goal Achievement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando os outliers\n",
    "sns.boxplot(df_no_outliers['2016/17 Goal Achievement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- removendo os outliers\n",
    "df_no_outliers = df_no_outliers[(df_no_outliers['2015/16 Goal Achievement'] > 88) & (df_no_outliers['2015/16 Goal Achievement'] < 120)]\n",
    "df_no_outliers = df_no_outliers[(df_no_outliers['2016/17 Goal Achievement'] < 122) & (df_no_outliers['2016/17 Goal Achievement'] > 92)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando os ds\n",
    "X = df_no_outliers.drop(columns=['PROMOVIDO'])\n",
    "y = df_no_outliers['PROMOVIDO']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando o algoritmo\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando a matrix de confusão\n",
    "_ = plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as novas métricas\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização (ou standardization) dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- copiando o dataset\n",
    "df_standardized = df_dummies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- preparando os ds de análise\n",
    "X = df_standardized.drop(columns=['PROMOVIDO'])\n",
    "y = df_standardized['PROMOVIDO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- standarizando os dados\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled = pd.DataFrame(scaled_data, \n",
    "                        index=X.index,\n",
    "                        columns=X.columns)\n",
    "\n",
    "df_standardized = pd.concat([X_scaled, y], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando os dados do ds\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- separando as amostras de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando o algoritmo\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando a métrica de teste\n",
    "print(f'log loss (test): {log_loss(y_test, y_pred_proba):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando a ROC\n",
    "_= plot_roc_curve(logreg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- parametrizando o algoritmo de seleção das variáveis\n",
    "selector = RFECV(logreg, step=1, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando o algoritmo\n",
    "_ = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- apresentando a seleção\n",
    "pd.DataFrame(data=selector.support_,\n",
    "             columns=['support'],\n",
    "             index=X.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- apresentando a seleção\n",
    "pd.DataFrame(data=selector.ranking_,\n",
    "             columns=['support'],\n",
    "             index=X.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um novo dataset\n",
    "df_selection = selector.transform(X_train)\n",
    "df_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- selecionando a coluna de resposta\n",
    "y_pred_proba = selector.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- pritando a métrica de log loss\n",
    "print(f'log loss (test): {log_loss(y_test, y_pred_proba):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando a ROC\n",
    "_= plot_roc_curve(logreg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- checking multcolinearity\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- sorting data by multicolineatiry\n",
    "vif.round(1).sort_values(['VIF Factor'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- o moodelo está balanceado?\n",
    "pd.DataFrame(y)['PROMOVIDO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando o balanceamento\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "os_data_y = pd.DataFrame(data=os_data_y)\n",
    "\n",
    "#-- checando\n",
    "print(\"tamanho do dataset \",len(os_data_X))\n",
    "print(\"número de clientes com cancelamento\",len(os_data_y[os_data_y['PROMOVIDO']==0]))\n",
    "print(\"número de clientes sem cancelamento\",len(os_data_y[os_data_y['PROMOVIDO']==1]))\n",
    "print(\"proporção de com cancelamento \",len(os_data_y[os_data_y['PROMOVIDO']==0])/len(os_data_X))\n",
    "print(\"proporção de sem cancelamento \",len(os_data_y[os_data_y['PROMOVIDO']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T00:54:53.293496Z",
     "start_time": "2019-01-28T00:54:53.287499Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg_up = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T00:55:07.337611Z",
     "start_time": "2019-01-28T00:54:56.145321Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg_up.fit(os_data_X, os_data_y)\n",
    "y_pred = logreg_up.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T00:55:10.298418Z",
     "start_time": "2019-01-28T00:55:10.289423Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy (test): {accuracy_test*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T00:55:13.370333Z",
     "start_time": "2019-01-28T00:55:13.350344Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T00:55:17.124337Z",
     "start_time": "2019-01-28T00:55:16.966594Z"
    }
   },
   "outputs": [],
   "source": [
    "#-- printando a matriz de confusão\n",
    "_ = plot_confusion_matrix(logreg_up, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as novas métricas\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos salvar o modelo para conseguirmos carregá-lo em análises futuras pós-aula.\n",
    "Para detalhes, veja a documentação do scikit-learn: [Model Persistence](http://scikit-learn.org/stable/modules/model_persistence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(logreg, '../models/logreg.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também salvar o dataset transformado, assim como foi utilizado pelo modelo final. Para facilitar a interpretação do modelo, salvaremos também uma versão para \"display\", que é sua versão antes da padronização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized.to_csv('../data/Base Analytics Processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
